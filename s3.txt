_____________________________________________________________________________________

S3 : Simple Storage Service : 
-
Object based storage :  We cannot install/run any applications/os. : Dropbox / GDrive 
--> Designed to flat files.

Block based storage : Designed to run OS, We can install/run applications.. : EBS, Instance store volumes. : EC2 
Storage over the network : Storage runs over the network and it can be mounted to multiple devices. : EFS, FSx : EC2

--> Designed to store objects. We can store any flat files.
--> We store data in BUCKETS. 
--> Bucket names should be unique across the globe. 
--> Defualtly, we can create 100 buckets, This is a soft limit. 
--> We can store unlimited data in a bucket.
--> No Pre-provisioning required.
--> Bucket naming limitations
	--> Min char 3, Max 63 char length
	--> Bucket name should be in small , and numeric
	--> Bucket name should not start with .
	--> Should not end with . , No adjesent ..
	--> Bucket name should not resemble IP address format. (192.168.100.1)

--> We can upload objects to this buckets.
--> Min obj size : 0 bytes.. Max Obj size: 5 TB
--> S3 is a global service. Doesn't required region selection.
--> While creating we need to choose the region. Data physically resides at this regions AZs. 

https://s3.ap-south-1.amazonaws.com/bucketname/objectname
https://bucketname.s3.ap-south-1.amazonaws.com/objectname (virtual path)
https://bucketname.s3.amazonaws.com/objectname (virtual path)

Virtual paths won't work if we have . in bucket names.

To make an object public : 

1. Block Public Access settings for this account : Account Level Blocking
2. Block public access (bucket settings) : Bucket level Blocking
--> We should make an object public, then only Object URLs works.
Object Ownership : ACLs enabled
3. Make object public

S3 Free Tier ELigibility : 
5 GB Standard Storage
--> 2000 PUT (Upload) / 20,000 GET (Download)

Task : 
--> Enable "Free tier alerts". Login using root user/iam user with admin permissions..
Preferences --> Billing preferences --> Receive Free Tier Usage Alerts --> Enable and enter valid email address.

Task 2 : Create an s3 bucket, Upload an object, Make object public accesable.


_______________________________________________________________________________


GDrive : 100 gb plan				S3	: no pre provisioning req

20 gb Daily									S3-Standard
20 gb Infreq 								Standard-IA / OneZOne-IA
10 gb don't know when to access			Intelligent Tier
20 gb unimp data / non critical			RRS (Redused redundancy storage)
10 gb archive								Glacier / Glacier-DA

30gb

99.99% Ava
99.999999999 % Durability


S3 Storage Classes : 

--> S3 Standard : Defualt storage class for all the data we upload to s3. Data will be available immedeatly.
Designed to store : Frequently accessed data. 
Availability : 99.99%,  Durability: 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> Standard-IA : Data will be available immedeatly. Designed to store : infrequently accessed data
Avai : 99.9%, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> One Zone-IA : Data will be available immedeatly. Designed to store : infrequently accessed data. Store only non-critical data
Avai : 99.5 %, Durability : 99.999999999 (11 9's) 
Data replicates across : 1 AZs

--> Glacier Flexible Retrieval (Formerly Glacier) : Long-term data archiving with retrieval times ranging from minutes to hours. Data won't be available immedeatly. We need to initiate a data restration to view the data. Restoration takes (1 min - 5 Hrs)
Avai : 99.99 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> Glacier Instant Retrieval : Long-lived archive data accessed once a quarter with instant retrieval in milliseconds. 

--> Glacier Deep Archieve : Long-term data archiving with retrieval times ranging from 12 hrs. Data won't be available immedeatly. We need to initiate a data restration to view the data. Restoration takes (5 - 12 Hrs)
Avai : 99.99 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs
..
S3 Intelligent Tier : If we have unknown access pattern, we can choose. 
Avai : 99.9 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

RRS : Redused Redundancy Storage : Not Recommanded : Less durability.. 
Durability : 99.99%, As we have less durability we have high chances to loss the data when compared to another storage classes.


S3 Pricing : 
--> How much data we are storing.
--> How many GET/PUT operations (uploads/downloaded object count)
--> Data retrivals

Glacier data retrival : 
Bulk retrieval : Typically within 5-12 hours.
Standard retrieval : Typically within 3-5 hours.
Expedited retrieval : Typically within 1-5 minutes when retrieving less than 250 MB.


______________________________________________________________________________________

D: 11/05/2022

If you are typing "Delete" ==> you'll get delete Marker. 
If you are typing "perm Delete" ==> You wont get Delete marker.

_________

Version : AWS maintains multiple copies in s3 bucket. 
--> Defaultly versioning will be in Suspended state.
--> When versioning is enabled, If we delete an object

Versioning : HIDE
--> S3 will show most recent uploaded object only / Current version objects.
--> We will get a Delete Marker. 
--> TO get object back / undo delete, Set Version to SHOW, Delete the delete marker.

Versioning : SHOW
--> If we delete an object, it deletes permanently.

_____________________________________________________________________________________

Life Cycle Management Rule : 
--> We can apply Rule to entire bucket
--> We can limit rule to a prefix (Folder)
--> We can limit rule to objects by specifing a "Tag"


S3 Standard --> StandardIA --> Glacier --> Delete
S3 Standard --> Glacier --> Delete
S3 Standard --> Delete


Task : Create a Life CYcle management rule to transit corrent version objects from s3 standard to Delete after 2 Days.
Transit previous version objects to Delete after 1 Day. 



_______________________________________________________________________________________

D: 12/05/2022

CRR / SRR : 
--> Source bucket and destination bucket must be enabled with versioning. 
--> Existing objects will not replicate to the destination bucket.
--> All future / subsequent uploads will replicate to destination bucket. 

RTC : Replication time control : Data replicates to destination bucket with in 15 Min. (99.99% of the data) : COST US

___
Data transfer from One region to another region "cost us".
Data transfer within a region won't cost us anything.
_______________________

aws s3 sync s3://source s3://target		==> 12:00AM   (task scheduler / cron job)
_______________________


Task : Create an S3 bucket, Upload some data, Enable versioning.. Upload same data again multiple times.. 

Configure Life cycle management rule to Transit objects from S3 standard to Delete after 3 Days.. Previous versions should delete after 2 days.

Task 2 : Configure Same Region Replication.. (Source bucket and target bucket should run with S3-Standard storage class only)

____________________________________________

S3 Static Website Hostic : 

--> We need to make data public read, then only our website will deliver. 
--> Purchased Domain name should be same as Bucket name. 
http://learnaws.co.in.s3-website.ap-south-1.amazonaws.com  ==> learnaws.co.in

http status codes :
2XX : OK/Success
3XX : Redirection
4XX : Client sider error
5XX : Server sider error


Task : Download a template from Internet. Deliver the webiste using s3- static webiste feature.


Slack Channel Link : https://join.slack.com/t/awswithavinash/shared_invite/zt-ozg7f9gx-lGdrFMlaOAc_BiPl4V~f4w

_______________________________________________________________________________________

D: 13/05/2022

--> In-Transit Encryption : 
	SSL (Secure socket layer) / TLS (Transport layer secure)

--> SSE (Server Side Encryption) / At-rest : 

SSE-S3 : S3 platform generates and manages the key material. whoever have valid access on S3 platform can decrypt/view the data. (An encryption key that Amazon S3 creates, manages, and uses for you).

SSE-KMS : Key Management Service : 
	KMS (AWS managed keys) (aws/s3) DMK(Default Master Key) : KMS Service generates and manages the key material. whoever have valid access on S3 platform can decrypt/view the data. We cannot delete these keys. 
	 CMK (Customer managed keys) : KMS Service generates and manages the keymaterial.
Along with S3 platform, the IAM user need to have valid permissions on ENCRYPTION KEY also. NO FREE TIER ELIGIBILITY.
	SSE-C (Customer Provided Key): Customer generates and upload the key material to KMS and KMS uses this key material to encrypt/decrypt the data. CUstomer can change the key material at any time. NO FREE TIER ELIGIBILITY.

--> CSE (Client Side Encryption) : 
Before uploading data to s3 platform, we can use our own software/applications to encrypt the data. That encryptrd data we can send to s3. AWS is not completely responsible for this mechanism.


Encryption key generation : 
--> Choose key type : Symmetric /Asymetric
--> Choose key Administrator
--> Choose Key Users
--> Review and create

____________________________________________________________________________


Server access logging : enable logging on bucket.

https://docs.aws.amazon.com/AmazonS3/latest/userguide/LogFormat.html

Cloudtrail : Data events : It allow us to log all s3 activities (Current buckets and future buckets).
____________


Event notifications : 

--> SNS : Simple Notification Service : 1000 EMAILs Free Tier eligibility
--> SQS : Simple Queue Service
--> Lambda 

--> Make sure you edit the SNS topic's "Access Policy to everyone".

____________


Task : Create an S3 Bucket, Create an SNS topic add a subscriber.. Configure Events on s3 to trigger an email when Object creation and deletion happend.

Task 2 : Enable Encryption on s3 bucket and test it. (SSE-S3/AWS Managed key)

_______________________________________________________________________________

D: 16/05/2022

Requirement : IAM user has its s3 bucket, he need to get access on his own bucket. : IAM Policy
https://s3.console.aws.amazon.com/s3/buckets/bucketname

Requirement : IAM User has s3 full access, But i want to limit this user access on "one particular" bucket. 

Deny upload object operation on a particular bucket. : Bucket policy

Bucket ARN : arn:aws:s3:::avinash.bucket
IAM User ARN / Principal : arn:aws:iam::501170964283:user/s3user
Effect : Allow / Deny : Deny
Action / Operation : PutObject, DeleteBucket


Object level / Inside bucket possible operation : arn:aws:s3:::avinash.bucket/*
Bucket level : arn:aws:s3:::avinash.bucket

___________________


Requester pays : the requester pays for requests and data transfer costs, and anonymous access to this bucket is disabled. Instead of bucket owner data requester need to pay for the data transfer & request.
--> Anonomus access disables once we enable this feature.
_______

Transfer acceleration : Uses Edge locations for data transfer. (COST US)
S3 Transfer Acceleration is not supported for buckets with periods (.) in their names


https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html?region=ap-south-1&origBucketName=avinash2

Object Lock : 
--> Versioning must be enabled.
Permanently allows objects in this bucket to be locked. Additional Object Lock configuration is required in bucket details after bucket creation to protect objects in this bucket from being deleted or overwritten.

Governance : Users with specific IAM permissions can overwrite or delete protected object versions during the retention period.

Compliance : No users can overwrite or delete protected object versions during the retention period.
_____

Performance : 
3500 PUT Object per second per prefix
5500 GET Object per second per prefix

Increase the uniqueness for the object names.
Use more prefixes

School
Schools day 1
Photo2 

College
Photo3
Photo4

vacation
Photo5
photo6


______________________________________________________________________________________

D: 17/05/2022

Pricing : https://calculator.aws/
Free Tier : https://aws.amazon.com/free


Storage Class Analysis : Analyze storage access patterns to help you decide when to transition objects to the appropriate storage class. 

Cross-origin resource sharing (CORS)
The CORS configuration, written in JSON, defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.

________________________________________________________________________________


Performance : 

--> Increase the randomness in object names.
--> Use the prefixes. 

--> 3500 PUT/Sec.. 5500 GET/Sec.. If we are directly storing all data in s3 platform.

In S3, Perfix place imp role. /prefix we will get 3500 put & 5500 get operations.

Req: 35,000 PUT.. --> Create 10 folders and upload data simumtaniously. 

__________________

FOr Put of new object, "read after write consistency". (If upload success, we can start accessing the data without any delay)
Eventual consistenacy For overwrite an object / delete an object. (AFter delete shown as success, we may get response for the request for some milli seconds) (You have uploaded object with latest data and trying to access, you have chances to get previous data object) 

__________________

How to access s3 using 3rd party applications.!!
Ans : S3 Browser, CyberDuck, WinSCP, CLoudberry explorer

https://www.msp360.com/explorer/windows/amazon-s3.aspx


Task : Try any of the s3 supported 3rd party application. 

________________

If we have larger file to uploade to s3 paltform, We can initiate the "Multi Part Upload". 

_________________

AWS Snow Family : 
--> AWS snowcone : 8 TB
--> AWS Snowball : 100 TB
--> AWS Snowball edge : 40 - 100 TB
--> AWS Snow mobile : PB scale container

___

AWS Direct Connect : Dedicated connection between on-premise/local environment to AWS environment. 3-4 weeks time required. We need to choose the required bandwidth. 
--> Airtel, jio, sify

Site-to-site VPN : 

--> Storage classes
--> Versioning
--> LCR
--> CRR/SRR
--> Encryption
--> Bucket policy



https://join.slack.com/t/awswithavinash/shared_invite/zt-199j47781-bQMAvHc0gbGd04EtZbQevQ








